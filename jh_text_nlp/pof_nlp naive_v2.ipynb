{"cells":[{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, StringIndexer\nfrom pyspark.sql.functions import length, size\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\nimport nltk"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4400432230767252&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>sql <span class=\"ansigreen\">import</span> SQLContext<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> sqlContext <span class=\"ansiyellow\">=</span> SQLContext<span class=\"ansiyellow\">(</span>sc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 5</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">import</span> nltk<span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ImportError</span>: No module named &apos;nltk&apos;</div>"]}}],"execution_count":1},{"cell_type":"code","source":["##dataframe = sqlContext.read.format('csv').options(header='true', inferScheme='true').load('C:/Users/jazmi/OneDrive/Documents/DataMate/db/all.csv')\ndf = spark.table(\"all_csv\")\n\ndf.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>[&apos;_c0&apos;, &apos;username&apos;, &apos;Gender&apos;, &apos;Education&apos;, &apos;Ethnicity&apos;, &apos;about_me_text_clean&apos;]</div>"]}}],"execution_count":2},{"cell_type":"code","source":["df = df.select('username', 'about_me_text_clean', 'Gender').na.drop()\ndf_length = df.withColumn('length', length(df['about_me_text_clean']))\ndf_length.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+------+------+\n      username| about_me_text_clean|Gender|length|\n+--------------+--------------------+------+------+\n   ROXYCHIC549| I am not an upgr...|     F|  1615|\n tequilagirl69|Laid back lovable...|     F|   175|\natxredneckgirl|Tx country music ...|     F|   259|\n       mel12th|I am here to look...|     F|   338|\n    Andi010274|Cant get into my ...|     F|    47|\n       nodutch|Music business go...|     F|    67|\n      lauranmr|Of all the dating...|     F|   708|\n        smbd75|Likes fun adventu...|     F|    66|\n  candipie1989|Single black fema...|     F|   376|\n       tif1985|Im on here just l...|     F|   300|\n        De1964|Please local only...|     F|  1088|\n     Trini1971|I am a Mom to a 1...|     F|   564|\n    FiaFia1213|I like to think I...|     F|   341|\n    SweetJojos|     Up for anything|     F|    15|\n      Tawdra83|Iâ€™m a artist I co...|     F|   423|\n  LadyTexas254|not looking for a...|     F|   233|\n     Vigilia79|Hi there Im Chris...|     F|   607|\n     ayoung292|Music is life and...|     F|   102|\n Foreverfungrl|          Ask me Are|     F|    10|\n    southstar5|Single have two k...|     F|    39|\n+--------------+--------------------+------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["male_female_to_num = StringIndexer(inputCol='Gender', outputCol='label')\n\ntokened_df = Tokenizer(inputCol=\"about_me_text_clean\", outputCol=\"token_text\")\n\nstop_remove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n\nhashing = HashingTF(inputCol='token_text', outputCol=\"hashedValues\")\n\nidf = IDF(minDocFreq = 10, inputCol=\"hashedValues\", outputCol=\"idf_features\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import Vector\n\n# Create feature vectors\nclean_up = VectorAssembler(inputCols=['idf_features', 'length'], outputCol='features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml import Pipeline\ndata_prep_pipeline = Pipeline(stages=[male_female_to_num, tokened_df, stop_remove, hashing, idf, clean_up])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Fit and transform the pipeline\ncleaner = data_prep_pipeline.fit(df_length)\ncleaned = cleaner.transform(df_length)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Show label and resulting features\ncleaned.select(['label', 'features']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nlabel|            features|\n+-----+--------------------+\n  0.0|(262145,[4200,538...|\n  0.0|(262145,[4333,844...|\n  0.0|(262145,[9639,286...|\n  0.0|(262145,[14,9639,...|\n  0.0|(262145,[24417,37...|\n  0.0|(262145,[9639,572...|\n  0.0|(262145,[1998,961...|\n  0.0|(262145,[8443,199...|\n  0.0|(262145,[8449,134...|\n  0.0|(262145,[4200,576...|\n  0.0|(262145,[3326,408...|\n  0.0|(262145,[9639,129...|\n  0.0|(262145,[329,9639...|\n  0.0|(262145,[16332,10...|\n  0.0|(262145,[2437,963...|\n  0.0|(262145,[9988,133...|\n  0.0|(262145,[4200,963...|\n  0.0|(262145,[15889,24...|\n  0.0|(262145,[109810,1...|\n  0.0|(262145,[15664,23...|\n+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n# Break data down into a training set and a testing set\ntraining, testing = cleaned.randomSplit([0.7, 0.3])\n\n# Create a Naive Bayes model and fit training data\nnb = NaiveBayes()\npredictor = nb.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["test_results = predictor.transform(testing)\ntest_results.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n        username| about_me_text_clean|Gender|length|label|          token_text|         stop_tokens|        hashedValues|        idf_features|            features|       rawPrediction|         probability|prediction|\n+----------------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n       15winstom|Iam a traveler I ...|     M|   137|  1.0|[iam, a, traveler...|[iam, traveler, a...|(262144,[4788,609...|(262144,[4788,609...|(262145,[11724,24...|[-596.54913875400...|[0.99999999998621...|       0.0|\n         19edt70|Music snob love l...|     M|    26|  1.0|[music, snob, lov...|[music, snob, lov...|(262144,[33053,63...|(262144,[33053,63...|(262145,[33053,63...|[-69.046188189177...|[0.98566843209601...|       0.0|\n     1KindOfLove|Hi my name is She...|     F|   854|  0.0|[hi, my, name, is...|[hi, name, sheila...|(262144,[9639,144...|(262144,[9639,144...|(262145,[9639,144...|[-3274.6976735079...|[1.0,2.3281027418...|       0.0|\n1PrettyFeetChef1|BBW  Entrepreneur...|     F|   336|  0.0|[bbw, , entrepren...|[bbw, , entrepren...|(262144,[9639,163...|(262144,[9639,163...|(262145,[9639,163...|[-1089.4348342104...|[1.0,5.8482483106...|       0.0|\n      210Frances|Hello My name is ...|     F|   229|  0.0|[hello, my, name,...|[hello, name, fra...|(262144,[8443,158...|(262144,[8443,158...|(262145,[8443,158...|[-825.61464493235...|[1.0,6.8045269544...|       0.0|\n+----------------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nprint(\"Accuracy of model at predicting reviews was: %f\" % acc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of model at predicting reviews was: 0.375637\n</div>"]}}],"execution_count":11}],"metadata":{"name":"pof_nlp naive (1)","notebookId":4400432230767251},"nbformat":4,"nbformat_minor":0}
