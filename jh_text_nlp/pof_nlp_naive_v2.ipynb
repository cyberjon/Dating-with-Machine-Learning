{"cells":[{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, StringIndexer\nfrom pyspark.sql.functions import length, size\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["##dataframe = sqlContext.read.format('csv').options(header='true', inferScheme='true').load('C:/Users/jazmi/OneDrive/Documents/DataMate/db/all.csv')\ndf = spark.table(\"all_csv\")\n\ndf.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>[&apos;_c0&apos;, &apos;username&apos;, &apos;Gender&apos;, &apos;Education&apos;, &apos;Ethnicity&apos;, &apos;about_me_text&apos;]</div>"]}}],"execution_count":2},{"cell_type":"code","source":["df = df.select('username', 'about_me_text', 'Gender').na.drop()\ndf_length = df.withColumn('length', length(df['about_me_text']))\ndf_length.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+------+------+\n      username|       about_me_text|Gender|length|\n+--------------+--------------------+------+------+\nShortyFire1984|....................|     F|    30|\n   ROXYCHIC549|&apos;&quot; I am not an up...|     F|  1700|\n tequilagirl69|Laid back lovable...|     F|   181|\natxredneckgirl|Tx country music ...|     F|   284|\n       mel12th|I am here to look...|     F|   364|\n    Andi010274|Can&apos;t get into my...|     F|    49|\n       nodutch|Music business go...|     F|    67|\n      lauranmr|Of all the dating...|     F|   735|\n        smbd75|Likes: fun, adven...|     F|    73|\n  candipie1989|Single black fema...|     F|   385|\n       tif1985|I&apos;m on here just ...|     F|   309|\n        De1964|Please local only...|     F|  1118|\n     Trini1971|I am a Mom to a 1...|     F|   589|\n    FiaFia1213|I like to think I...|     F|   352|\n    SweetJojos|     Up for anything|     F|    15|\n      Tawdra83|Iâ€™m a artist. I c...|     F|   434|\n  LadyTexas254|not looking for a...|     F|   241|\n     Vigilia79|Hi there! I&apos;m Chr...|     F|   650|\n     ayoung292|Music is life and...|     F|   105|\n Foreverfungrl|          Ask me Are|     F|    10|\n+--------------+--------------------+------+------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["male_female_to_num = StringIndexer(inputCol='Gender', outputCol='label')\n\ntokened_df = Tokenizer(inputCol=\"about_me_text\", outputCol=\"token_text\")\n\nstop_remove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n\nhashing = HashingTF(inputCol='token_text', outputCol=\"hashedValues\")\n\nidf = IDF(minDocFreq = 10, inputCol=\"hashedValues\", outputCol=\"idf_features\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import Vector\n\n# Create feature vectors\nclean_up = VectorAssembler(inputCols=['idf_features', 'length'], outputCol='features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml import Pipeline\ndata_prep_pipeline = Pipeline(stages=[male_female_to_num, tokened_df, stop_remove, hashing, idf, clean_up])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Fit and transform the pipeline\ncleaner = data_prep_pipeline.fit(df_length)\ncleaned = cleaner.transform(df_length)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Show label and resulting features\ncleaned.select(['label', 'features']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+--------------------+\nlabel|            features|\n+-----+--------------------+\n  0.0|(262145,[262144],...|\n  0.0|(262145,[4054,538...|\n  0.0|(262145,[4333,844...|\n  0.0|(262145,[9639,390...|\n  0.0|(262145,[14,9639,...|\n  0.0|(262145,[18976,24...|\n  0.0|(262145,[9639,572...|\n  0.0|(262145,[1998,961...|\n  0.0|(262145,[224647,2...|\n  0.0|(262145,[8449,134...|\n  0.0|(262145,[4200,576...|\n  0.0|(262145,[1536,332...|\n  0.0|(262145,[2711,963...|\n  0.0|(262145,[329,9639...|\n  0.0|(262145,[16332,10...|\n  0.0|(262145,[2437,963...|\n  0.0|(262145,[13396,16...|\n  0.0|(262145,[456,4054...|\n  0.0|(262145,[2624,158...|\n  0.0|(262145,[109810,1...|\n+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\n# Break data down into a training set and a testing set\ntraining, testing = cleaned.randomSplit([0.7, 0.3])\n\n# Create a Naive Bayes model and fit training data\nnb = NaiveBayes()\npredictor = nb.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["test_results = predictor.transform(testing)\ntest_results.show(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n   username|       about_me_text|Gender|length|label|          token_text|         stop_tokens|        hashedValues|        idf_features|            features|       rawPrediction|         probability|prediction|\n+-----------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n 121121p012|Fun fun fun. Just...|     M|    46|  1.0|[fun, fun, fun., ...|[fun, fun, fun., ...|(262144,[8443,360...|(262144,[8443,360...|(262145,[8443,360...|[-237.06106696838...|[0.99999875948742...|       0.0|\n      1IHIH|Looking to meet s...|     M|   207|  1.0|[looking, to, mee...|[looking, meet, s...|(262144,[9639,192...|(262144,[9639,192...|(262145,[9639,192...|[-580.04675148955...|[1.0,3.9257032398...|       0.0|\n1KindOfLove|Hi, my name is Sh...|     F|   892|  0.0|[hi,, my, name, i...|[hi,, name, sheil...|(262144,[3358,751...|(262144,[3358,751...|(262145,[9639,158...|[-3028.0127871240...|[1.0,6.0578372449...|       0.0|\n    1STREAD|I LIKE MEN....5&quot;1...|     F|    91|  0.0|[i, like, men.......|[like, men....5&quot;1...|(262144,[24417,91...|(262144,[24417,91...|(262145,[24417,91...|[-194.24965259435...|[0.99999999991279...|       0.0|\n     1cyndi|Hello. Iâ€™m new to...|     F|   609|  0.0|[hello., iâ€™m, new...|[hello., iâ€™m, new...|(262144,[9639,133...|(262144,[9639,133...|(262145,[9639,163...|[-2187.5490360695...|[1.0,2.2283941737...|       0.0|\n+-----------+--------------------+------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nacc_eval = MulticlassClassificationEvaluator()\nacc = acc_eval.evaluate(test_results)\nprint(\"Accuracy of model at predicting reviews was: %f\" % acc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of model at predicting reviews was: 0.356641\n</div>"]}}],"execution_count":11}],"metadata":{"name":"pof_nlp naive (1)","notebookId":4400432230767251},"nbformat":4,"nbformat_minor":0}
