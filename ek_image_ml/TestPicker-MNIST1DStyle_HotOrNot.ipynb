{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# data-handling dependencies\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling & splitting\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading and Preprocessing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load the PlentyOfFish image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllieKat1070.00.png\n",
      "AllieKat1070.01.png\n",
      "amunyque71.00.png\n",
      "amunyque71.01.png\n",
      "amunyque71.02.png\n",
      "amunyque71.03.png\n",
      "amunyque71.04.png\n",
      "amunyque71.05.png\n",
      "antonia_men.00.png\n",
      "antonia_men.01.png\n",
      "antonia_men.02.png\n",
      "antonia_men.03.png\n",
      "antonia_men.04.png\n",
      "antonia_men.05.png\n",
      "BeePatient.00.png\n",
      "BeePatient.01.png\n",
      "BeePatient.02.png\n",
      "BeePatient.03.png\n",
      "BeePatient.04.png\n",
      "BeePatient.05.png\n",
      "candipie1989.00.png\n",
      "candipie1989.01.png\n",
      "candipie1989.02.png\n",
      "candipie1989.03.png\n",
      "candipie1989.04.png\n",
      "candipie1989.05.png\n",
      "candipie1989.06.png\n",
      "carmelreed.00.png\n",
      "carmelreed.01.png\n",
      "carmelreed.02.png\n",
      "carmelreed.03.png\n",
      "carmelreed.04.png\n",
      "carmelreed.05.png\n",
      "cherryandsandy.00.png\n",
      "chloe0219.00.png\n",
      "chloe0219.01.png\n",
      "chloe0219.02.png\n",
      "chloe0219.03.png\n",
      "chloe0219.04.png\n",
      "chloe0219.05.png\n",
      "chloe0219.06.png\n",
      "chloe0219.07.png\n",
      "consuelocast.00.png\n",
      "cristinabele.00.png\n",
      "cristinabele.01.png\n",
      "danigirl1234e.00.png\n",
      "danigirl1234e.01.png\n",
      "danigirl1234e.02.png\n",
      "danigirl1234e.03.png\n",
      "Erickadh2.00.png\n",
      "Erickadh2.01.png\n",
      "Erickadh2.02.png\n",
      "GeekyLonghorn.00.png\n",
      "GeekyLonghorn.01.png\n",
      "GeekyLonghorn.02.png\n",
      "GeekyLonghorn.03.png\n",
      "GeekyLonghorn.04.png\n",
      "GeekyLonghorn.05.png\n",
      "GeekyLonghorn.06.png\n",
      "heidiatx.00.png\n",
      "heidiatx.01.png\n",
      "heidiatx.02.png\n",
      "heidiatx.03.png\n",
      "heidiatx.04.png\n",
      "heidiatx.05.png\n",
      "Hpolvr71.00.png\n",
      "Hpolvr71.01.png\n",
      "Hpolvr71.02.png\n",
      "Hpolvr71.03.png\n",
      "Hpolvr71.04.png\n",
      "Hpolvr71.05.png\n",
      "Hpolvr71.06.png\n",
      "Hpolvr71.07.png\n",
      "jacklina1.00.png\n",
      "jacklina1.01.png\n",
      "jacklina1.02.png\n",
      "Jensta11.00.png\n",
      "Jensta11.01.png\n",
      "Jensta11.02.png\n",
      "Jensta11.03.png\n",
      "karyn1916.00.png\n",
      "karyn1916.01.png\n",
      "karyn1916.02.png\n",
      "karyn1916.03.png\n",
      "khendab.00.png\n",
      "khendab.01.png\n",
      "khendab.02.png\n",
      "khendab.03.png\n",
      "khendab.04.png\n",
      "khendab.05.png\n",
      "khendab.06.png\n",
      "ladylisau.00.png\n",
      "ladylisau.01.png\n",
      "ladylisau.02.png\n",
      "ladylisau.03.png\n",
      "Lashae42.00.png\n",
      "LearJetLover.00.png\n",
      "LearJetLover.01.png\n",
      "LearJetLover.02.png\n",
      "LearJetLover.03.png\n",
      "LikelyToLove.00.png\n",
      "LikelyToLove.01.png\n",
      "LikelyToLove.02.png\n",
      "luvspink.00.png\n",
      "maryannbella.00.png\n",
      "mmorgan17.00.png\n",
      "mmorgan17.01.png\n",
      "mmorgan17.02.png\n",
      "mmorgan17.03.png\n",
      "mmorgan17.04.png\n",
      "mmorgan17.05.png\n",
      "mrosebud1971.00.png\n",
      "NoooDramaJustFun.00.png\n",
      "NoooDramaJustFun.01.png\n",
      "NoooDramaJustFun.02.png\n",
      "NoooDramaJustFun.03.png\n",
      "NoooDramaJustFun.04.png\n",
      "NoooDramaJustFun.05.png\n",
      "NoooDramaJustFun.06.png\n",
      "NoooDramaJustFun.07.png\n",
      "Once_moreTime0998655.00.png\n",
      "peggyrm1.00.png\n",
      "peggyrm1.01.png\n",
      "peggyrm1.02.png\n",
      "peggyrm1.03.png\n",
      "peggyrm1.04.png\n",
      "peggyrm1.05.png\n",
      "peggyrm1.06.png\n",
      "peggyrm1.07.png\n",
      "pjracer.00.png\n",
      "pjracer.01.png\n",
      "pjracer.02.png\n",
      "pjracer.03.png\n",
      "pjracer.04.png\n",
      "pjracer.05.png\n",
      "pjracer.06.png\n",
      "pjracer.07.png\n",
      "RarePattern.00.png\n",
      "RarePattern.01.png\n",
      "RarePattern.02.png\n",
      "RarePattern.03.png\n",
      "RarePattern.04.png\n",
      "RarePattern.05.png\n",
      "RarePattern.06.png\n",
      "RarePattern.07.png\n",
      "RED78752.00.png\n",
      "RED78752.01.png\n",
      "RED78752.02.png\n",
      "RED78752.03.png\n",
      "RED78752.04.png\n",
      "RED78752.05.png\n",
      "RED78752.06.png\n",
      "RED78752.07.png\n",
      "riverdancer526.00.png\n",
      "riverdancer526.01.png\n",
      "riverdancer526.02.png\n",
      "riverdancer526.03.png\n",
      "riverdancer526.04.png\n",
      "riverdancer526.05.png\n",
      "riverdancer526.06.png\n",
      "riverdancer526.07.png\n",
      "robbier718.00.png\n",
      "robbier718.01.png\n",
      "robbier718.02.png\n",
      "robbier718.03.png\n",
      "robbier718.04.png\n",
      "robbier718.05.png\n",
      "robbier718.06.png\n",
      "RRTX2014.00.png\n",
      "RRTX2014.01.png\n",
      "Seekingpassionatekisses.00.png\n",
      "Seekingpassionatekisses.01.png\n",
      "Seekingpassionatekisses.02.png\n",
      "Seekingpassionatekisses.03.png\n",
      "Seekingpassionatekisses.04.png\n",
      "Seekingpassionatekisses.05.png\n",
      "Seekingpassionatekisses.06.png\n",
      "Seekingpassionatekisses.07.png\n",
      "Seekingpassionatekisses.08.png\n",
      "Seekingpassionatekisses.09.png\n",
      "Seekingpassionatekisses.10.png\n",
      "Seekingpassionatekisses.11.png\n",
      "Seekingpassionatekisses.12.png\n",
      "Seekingpassionatekisses.13.png\n",
      "Seekingpassionatekisses.14.png\n",
      "Seekingpassionatekisses.15.png\n",
      "sexythick001.00.png\n",
      "sexythick001.01.png\n",
      "sexythick001.02.png\n",
      "singlediva14.00.png\n",
      "singlediva14.01.png\n",
      "Susie1119.00.png\n",
      "Susie1119.01.png\n",
      "Susie1119.02.png\n",
      "Susie1119.03.png\n",
      "Susie1119.04.png\n",
      "Susie1119.05.png\n",
      "Susie1119.06.png\n",
      "Susie1119.07.png\n",
      "SWWEscape.00.png\n",
      "SWWEscape.01.png\n",
      "SWWEscape.02.png\n",
      "SWWEscape.03.png\n",
      "SWWEscape.04.png\n",
      "tamarafer1225.00.png\n",
      "terriann0131.00.png\n",
      "terriann0131.01.png\n",
      "terriann0131.02.png\n",
      "terriann0131.03.png\n",
      "terriann0131.04.png\n",
      "terriann0131.05.png\n",
      "terriann0131.06.png\n",
      "Texas49.00.png\n",
      "Texas49.01.png\n",
      "Texas49.02.png\n",
      "Texas49.03.png\n",
      "Texas49.04.png\n",
      "Texas49.05.png\n",
      "tonyasandy.00.png\n",
      "tonyasandy.01.png\n",
      "TxSexyRed.00.png\n",
      "TxSexyRed.01.png\n",
      "TxSexyRed.02.png\n",
      "TxSexyRed.03.png\n",
      "TxSexyRed.04.png\n",
      "ykceb08.00.png\n"
     ]
    }
   ],
   "source": [
    "strImgPath = '../ek_scrape/img/doctordata/MyCity'\n",
    "lstImg = []\n",
    "for root, dirs, lstFile in os.walk(strImgPath):\n",
    "    lstFile.sort(key=str.lower)\n",
    "    for strFile in lstFile:\n",
    "        if strFile[-4:] == '.png':\n",
    "            print(strFile)\n",
    "            img = pyplot.imread(strImgPath + '/' + strFile, format='jpg')\n",
    "            arrImg = image.img_to_array(img)\n",
    "            lstImg.append(arrImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226, 110, 110, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrX = np.array(lstImg)\n",
    "arrX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfY = pd.read_csv('doctordata_MyCity.csv')\n",
    "arrY = np.array(dfY['interested'])\n",
    "arrY.shape\n",
    "arrY.ndim\n",
    "arrY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Train and Test datasets\n",
    "arrTrainX, arrTestX, arrTrainY, arrTestY = train_test_split(arrX, arrY, random_state=17) # , stratify=arrY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For Logistic Regression, we want to flatten our data into rows of 1D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (169, 36300)\n",
      "Testing Shape: (57, 36300)\n"
     ]
    }
   ],
   "source": [
    "# transform the 110x110x3 pics to a flat 1D array\n",
    "fltDimCount = arrTrainX.shape[1] * arrTrainX.shape[2] * arrTrainX.shape[3]\n",
    "arrTrainX = arrTrainX.reshape(arrTrainX.shape[0], fltDimCount)\n",
    "arrTestX = arrTestX.reshape(arrTestX.shape[0], fltDimCount)\n",
    "print(\"Training Shape:\", arrTrainX.shape)\n",
    "print(\"Testing Shape:\", arrTestX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# normalize training data\n",
    "scaler = MinMaxScaler().fit(arrTrainX)\n",
    "arrTrainX = scaler.transform(arrTrainX)\n",
    "arrTestX = scaler.transform(arrTestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our first step is to create an empty sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create first hidden layer, 100 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(100, activation='relu', input_dim=arrTrainX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create second hidden layer, 100 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our final output layer uses a `softmax` activation function for logistic regression.\n",
    "\n",
    "We also need to specify the number of output classes. In this case, the number of digits that we wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# final output layer: number of nodes must equal number of y labels.\n",
    "# IMPORTANT: for a single yes/no decision, activation is sigmoid, not softmax\n",
    "# see https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compile and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# uses categorical hinge for \"interested\" (1) and \"not interested\" (0)\n",
    "# IMPORTANT: for a single yes/no decision, loss is binary_crossentropy, not categorical_crossentropy\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) # binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Finally, we train our model using our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Training consists of updating our weights using our optimizer and loss function. In this example, we choose 10 iterations (loops) of training that are called epochs.\n",
    "\n",
    "We also choose to shuffle our training data and increase the detail printed out during each training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      " - 1s - loss: 2.4417 - acc: 0.7041\n",
      "Epoch 2/5\n",
      " - 0s - loss: 2.3843 - acc: 0.8521\n",
      "Epoch 3/5\n",
      " - 0s - loss: 2.3843 - acc: 0.8521\n",
      "Epoch 4/5\n",
      " - 0s - loss: 2.3843 - acc: 0.8521\n",
      "Epoch 5/5\n",
      " - 0s - loss: 2.3843 - acc: 0.8521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f1c9e3e710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    arrTrainX,\n",
    "    arrTrainY,\n",
    "    epochs=5,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('MNIST1DStyle_doctordata_MyCity.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 2.5450 - acc: 0.8421\n",
      "Loss: 2.544962445894877, Accuracy: 0.8421052694320679\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data \n",
    "fltLoss, fltAccuracy = model.evaluate(arrTestX, arrTestY, verbose=2)\n",
    "print(f'Loss: {fltLoss}, Accuracy: {fltAccuracy}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
